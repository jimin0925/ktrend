import os
import asyncio
import json
from openai import AsyncOpenAI
from dotenv import load_dotenv
from backend.database import Database

# Load env to get OPENAI_API_KEY
load_dotenv()

class TrendAnalyzer:
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if self.api_key:
            self.client = AsyncOpenAI(api_key=self.api_key)
        else:
            self.client = None
            print("[WARNING] No OPENAI_API_KEY found. Analyzer will return mock data.")
            
        # Database
        self.db = Database()

    async def analyze_trend(self, keyword: str):
        """
        Analyze trend using OpenAI's Native Web Search (Implicit) + Naver Datalab Data.
        Returns:
            dict: { "keyword": str, "reason": str, "chart_data": list }
        """
        if not self.client:
            return self._get_mock_analysis(keyword)

        # 1. Fetch Naver Datalab Data (Async wrap)
        from backend.services.naver_datalab import NaverDataLab
        try:
            datalab_service = NaverDataLab()
            chart_data = await asyncio.to_thread(datalab_service.get_daily_trend, keyword, days=365)
            
            # Create a summary for LLM context
            if chart_data:
                peak = max(chart_data, key=lambda x: x['ratio'])
                recent = chart_data[-1] if chart_data else None
                data_context = f"ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ì¶”ì´ (1ë…„): {chart_data[0]['date']}~{chart_data[-1]['date']}. ìµœê³ ì : {peak['date']} ({peak['ratio']}). ìµœê·¼: {recent['date']} ({recent['ratio']})."
            else:
                data_context = "ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì—†ìŒ."
        except Exception as e:
            print(f"Naver DataLab Error: {e}")
            chart_data = []
            data_context = "ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨."

        # 2. Check Database for Cached Reason
        cached_analysis = self.db.get_analysis(keyword)
        if cached_analysis:
            print(f"[DB HIT] Returning stored analysis for '{keyword}'")
            return {
                "keyword": keyword,
                "reason": cached_analysis["reason"],
                "chart_data": chart_data # Always return fresh chart data + cached reason
            }

        print(f"Analyzing trend for: {keyword} (LLM Call)...")
        
        # 3. LLM Analysis
        system_prompt = """
        ë„ˆëŠ” í•œêµ­ì˜ ìµœì‹  íŠ¸ë Œë“œë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼.
        **ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥**ì„ ì‚¬ìš©í•˜ì—¬ ì´ í‚¤ì›Œë“œê°€ **ì™œ** ìœ í–‰í•˜ëŠ”ì§€ ì •í™•í•œ 'ìœ ë˜'ì™€ 'ì´ìœ 'ë¥¼ ì°¾ì•„ë‚´.

        **ë¶„ì„ ê°€ì´ë“œë¼ì¸ (ì¤‘ìš”)**:
        í‚¤ì›Œë“œë¥¼ ë‹¤ìŒ 3ê°€ì§€ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•˜ì—¬ ë¶„ì„í•´:

        1. **ğŸ”¥ ë°”ì´ëŸ´ íŠ¸ë Œë“œ (Viral Trend) & íŒŒìƒ ìœ í–‰**:
           - ìµœê·¼ ë‰´ìŠ¤, ë°ˆ, ë°©ì†¡, SNS ë“±ì—ì„œ í™”ì œê°€ ë˜ì–´ ê¸‰ìƒìŠ¹í•œ ê²½ìš°.
           - **[ì¤‘ìš”] ì‹ì¬ë£Œ/ë¶€ì†í’ˆì¼ ê²½ìš°**: ì´ ì¬ë£Œê°€ ë“¤ì–´ê°€ëŠ” **ìƒìœ„ ìœ í–‰(Parent Trend)**ì´ ìˆëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸í•´.
             - ì˜ˆ: 'í”¼ìŠ¤íƒ€ì¹˜ì˜¤ ìŠ¤í”„ë ˆë“œ', 'ì¹´ë‹¤ì´í”„' -> 'ë‘ë°”ì´ ì´ˆì½œë¦¿'ì˜ í•µì‹¬ ì¬ë£Œë¼ì„œ ìœ í–‰í•¨. (ë‹¨ë… ìœ í–‰ ì•„ë‹˜)
             - ì˜ˆ: 'ê·¸ë¦­ìš”ê±°íŠ¸' -> 'ìš”ê±°íŠ¸ ì•„ì´ìŠ¤í¬ë¦¼(ìš”ì•„ì •)' í† í•‘ìœ¼ë¡œ ìœ í–‰í•¨.
           - ë¶„ì„: "OOOì˜ í•µì‹¬ ì¬ë£Œ/ë¶€ì†í’ˆìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤"ë¼ê³  ì¸ê³¼ê´€ê³„ë¥¼ ëª…í™•íˆ ì„¤ëª….

        2. **ğŸ‚ ê³„ì ˆ/ë‚ ì”¨ í•„ìˆ˜ê°€ (Seasonal Necessity)**:
           - íŠ¹ë³„í•œ ë‰´ìŠ¤ ì—†ì´, ë‚ ì”¨ë‚˜ ì‹œì¦Œ(ëª…ì ˆ, íœ´ê°€ì² ) ë•Œë¬¸ì— ì°¾ëŠ” ê²½ìš°.
           - ë¶„ì„: í˜„ì¬ ì‹œê¸°(ê³„ì ˆ)ì™€ì˜ ì—°ê´€ì„±ì„ ì„¤ëª….

        3. **ğŸ›’ ìƒí•„í’ˆ/ìŠ¤í…Œë””ì…€ëŸ¬ (Steady Seller)**:
           - ìœ í–‰ê³¼ ìƒê´€ì—†ì´ í•­ìƒ ìˆ˜ìš”ê°€ ê¾¸ì¤€í•œ ìƒí•„í’ˆì´ë‚˜ ì‹ì¬ë£Œ.
           - ë¶„ì„: "ì¼ìƒì ìœ¼ë¡œ ê¾¸ì¤€íˆ ì†Œë¹„ë˜ëŠ” í•„ìˆ˜í’ˆì…ë‹ˆë‹¤"ë¼ê³  ì„¤ëª….

        **í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€**:
        - 'ë‘ë°”ì´ ì«€ë“ì¿ í‚¤' -> ë‘ë°”ì´ì‚°ì´ ì•„ë‹ˆë¼ 'í•œêµ­ ì¹´í˜ì—ì„œ ìœ í–‰í•˜ëŠ” ë””ì €íŠ¸'ì¼ ìˆ˜ ìˆìŒ. í•œêµ­ ì›¹(ë‚˜ë¬´ìœ„í‚¤, ë¸”ë¡œê·¸) ìœ„ì£¼ë¡œ ê²€ìƒ‰í•´.
        
        **ì‘ë‹µ ìŠ¤íƒ€ì¼ (ë§¤ìš° ì¤‘ìš”)**:
        - **ë³¼ë“œì²´(**)**, **[ë§í¬]** ë“± ëª¨ë“  ì„œì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ˆ.** (ìˆœìˆ˜í•œ ì¤„ê¸€ í…ìŠ¤íŠ¸ë§Œ)
        - "ë¶„ì„ ê²°ê³¼: ..." ê°™ì€ ì„œë‘ ì—†ì´ ë°”ë¡œ ë³¸ë¡ ë§Œ ì‘ì„±í•´.
        - **[ìˆ˜ì¹˜ ì–¸ê¸‰ ê¸ˆì§€]**: "100ì„ ê¸°ë¡í–ˆë‹¤", "ratio 90" ê°™ì€ êµ¬ì²´ì ì¸ ìˆ«ìëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆ. ëŒ€ì‹  "ê¸‰ì¦í–ˆë‹¤", "ê¾¸ì¤€íˆ ë†’ì€ ì¸ê¸°ë¥¼ ìœ ì§€í•˜ê³  ìˆë‹¤", "ë‹¤ì†Œ ê°ì†Œí–ˆë‹¤" ê°™ì€ **ì •ì„±ì ì¸ í‘œí˜„**ì„ ì‚¬ìš©í•´.
        - ì œê³µëœ 'ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ì¶”ì´' ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ì¶”ì„¸(Trend)ë¥¼ ì„¤ëª…í•´.
        """

        user_prompt = f"""
        í‚¤ì›Œë“œ: '{keyword}'ì˜ ì •í™•í•œ í•œêµ­ ë‚´ ìœ í–‰ ì´ìœ ì™€ ìœ ë˜ë¥¼ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ë¶„ì„í•´ì¤˜.
        
        [ì°¸ê³  ë°ì´í„°]
        {data_context}
        """
        
        try:
            # Native Web Search - Implicit (JSON mode not supported with search)
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini-search-preview", 
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            )
            
            content = response.choices[0].message.content
            
            # Post-processing: Remove Markdown formatting (links, bold)
            import re
            # Remove links [text](url) -> text
            content = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', content)
            # Remove bold **text** -> text
            content = re.sub(r'\*\*([^*]+)\*\*', r'\1', content)
            # Remove bold __text__ -> text
            content = re.sub(r'__([^_]+)__', r'\1', content)
            
            # Save to DB
            self.db.save_analysis(keyword, content, chart_data)
            
            return {
                "keyword": keyword,
                "reason": content,
                "chart_data": chart_data
            }
            
        except Exception as e:
            print(f"LLM/Search error: {e}")
            return self._get_mock_analysis(keyword)

    def _get_mock_analysis(self, keyword):
        return {
            "keyword": keyword,
            "reason": "AI ë¶„ì„ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì„ì‹œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
            "chart_data": []
        }

